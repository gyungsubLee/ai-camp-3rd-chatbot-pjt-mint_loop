"""Chat Agent ì›Œí¬í”Œë¡œìš° ë…¸ë“œ

ê° ë…¸ë“œëŠ” ChatStateë¥¼ ë°›ì•„ ë¶€ë¶„ ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
"""
import json
from typing import Any

import structlog
from langchain_core.messages import AIMessage, HumanMessage

from .state import (
    ChatState,
    CollectedData,
    RejectedItems,
    DEFAULT_COLLECTED_DATA,
    DEFAULT_REJECTED_ITEMS,
)

logger = structlog.get_logger(__name__)


# =============================================================================
# ìƒìˆ˜ ì •ì˜
# =============================================================================

# ë‹¨ê³„ ì „í™˜ ë§µ
STEP_TRANSITIONS = {
    "greeting": "city",
    "city": "spot",
    "spot": "action",
    "action": "concept",
    "concept": "outfit",
    "outfit": "pose",
    "pose": "film",
    "film": "camera",
    "camera": "complete",
    "complete": "complete",
}

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
CHAT_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ Trip Kitì˜ íŠ¸ë˜ë¸” íë ˆì´í„°ì…ë‹ˆë‹¤. ë”°ëœ»í•˜ê³  ê°ì„±ì ì¸ ì—¬í–‰ ì „ë¬¸ê°€ë¡œì„œ ì‚¬ìš©ìì™€ ëŒ€í™”í•©ë‹ˆë‹¤.

## ì •ë³´ ìˆ˜ì§‘ ìˆœì„œ
ë„ì‹œ(city) â†’ ì¥ì†Œ(spotName) â†’ í–‰ë™(mainAction) â†’ ì»¨ì…‰(conceptId) â†’ ì˜ìƒ(outfitStyle) â†’ í¬ì¦ˆ(posePreference) â†’ í•„ë¦„(filmType) â†’ ì¹´ë©”ë¼(cameraModel)

## ì»¨ì…‰ ì˜µì…˜
flaneur(ë„ì‹œ ì‚°ì±…ì), filmlog(í•„ë¦„ ê°ì„±), midnight(ë°¤ì˜ ë‚­ë§Œ), pastoral(ì „ì›í’), noir(ì‹œë„¤ë§ˆí‹±), seaside(ë°”ë‹¤ ê°ì„±)

## Step-by-Step ì²˜ë¦¬ ë°©ë²•
ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë°›ìœ¼ë©´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆœì„œëŒ€ë¡œ ìˆ˜í–‰í•˜ì„¸ìš”:

**Step 1: ë©”ì‹œì§€ ë¶„ì„**
- ì‚¬ìš©ìê°€ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí–ˆëŠ”ê°€? (ì˜ˆ: "íŒŒë¦¬", "ì—í íƒ‘", "ì»¤í”¼")
- ì¶”ì²œì„ ìš”ì²­í–ˆëŠ”ê°€? (ì˜ˆ: "ì¶”ì²œí•´ì¤˜", "ì•„ë¬´ê±°ë‚˜", "ê³¨ë¼ì¤˜")
- ê±°ë¶€ ì˜ì‚¬ë¥¼ í‘œí˜„í–ˆëŠ”ê°€? (ì˜ˆ: "ì‹«ì–´", "ë³„ë¡œ", "ë‹¤ë¥¸ ê±°")

**Step 2: ì •ë³´ ì¶”ì¶œ ë° ì €ì¥**
- êµ¬ì²´ì  ì •ë³´ â†’ collectedDataì— ì €ì¥
- ì¶”ì²œ ìš”ì²­ â†’ ì°½ì˜ì ì¸ ì¶”ì²œì„ ìƒì„±í•˜ê³  collectedDataì— ì €ì¥
- ê±°ë¶€ â†’ rejectedItemsì— ì¶”ê°€
- ì—¬ëŸ¬ ì •ë³´ê°€ ìˆìœ¼ë©´ ëª¨ë‘ ì¶”ì¶œ (ì˜ˆ: "íŒŒë¦¬ ì—í íƒ‘ì—ì„œ ì»¤í”¼" â†’ city="íŒŒë¦¬", spotName="ì—í íƒ‘", mainAction="ì»¤í”¼ ë§ˆì‹œê¸°")

**Step 3: ì‘ë‹µ ìƒì„±**
- ì‚¬ìš©ì ì„ íƒ/ì¶”ì²œì— ëŒ€í•´ ê³µê°í•˜ê³  ì¹­ì°¬
- ë‹¤ìŒ ìˆ˜ì§‘ ëŒ€ìƒì— ëŒ€í•´ ìì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸
- ë”°ëœ»í•œ ì¡´ëŒ“ë§ê³¼ ì ì ˆí•œ ì´ëª¨ì§€ ì‚¬ìš©

## ì¶”ì²œ ìš”ì²­ ì˜ˆì‹œ
- "ë„ì‹œ ì¶”ì²œí•´ì¤˜" â†’ city="êµí† " ì €ì¥ + "ì¼ë³¸ êµí† ëŠ” ì–´ë– ì„¸ìš”? ğŸ‹"
- "ì¥ì†ŒëŠ” ì•„ë¬´ê±°ë‚˜" â†’ spotName="ê¸°ì˜¨ ê±°ë¦¬" ì €ì¥ + "ê¸°ì˜¨ ê±°ë¦¬ ì¶”ì²œë“œë ¤ìš”! ğŸ®"
- "ì»¨ì…‰ ê³¨ë¼ì¤˜" â†’ conceptId="filmlog" ì €ì¥ + "filmlog ì»¨ì…‰ ì¶”ì²œë“œë ¤ìš”! ğŸ“·"

## JSON ì‘ë‹µ í˜•ì‹
{"reply":"ë”°ëœ»í•œ ë©”ì‹œì§€","currentStep":"í˜„ì¬ë‹¨ê³„","nextStep":"ë‹¤ìŒë‹¨ê³„","isComplete":false,"collectedData":{"city":null,"spotName":null,"mainAction":null,"conceptId":null,"outfitStyle":null,"posePreference":null,"filmType":null,"cameraModel":null},"rejectedItems":{"cities":[],"spots":[],"actions":[],"concepts":[],"outfits":[],"poses":[],"films":[],"cameras":[]},"suggestedOptions":[]}

âš ï¸ ì¤‘ìš”: ì´ë¯¸ ìˆ˜ì§‘ëœ collectedData ê°’ì€ ì ˆëŒ€ nullë¡œ ë®ì–´ì“°ì§€ ë§ˆì„¸ìš”."""


# =============================================================================
# ë…¸ë“œ í•¨ìˆ˜ë“¤
# =============================================================================

async def process_message_node(
    state: ChatState,
    llm_provider: Any,
) -> dict:
    """ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬ ë° LLM í˜¸ì¶œ

    Args:
        state: í˜„ì¬ ëŒ€í™” ìƒíƒœ
        llm_provider: LLM Provider ì¸ìŠ¤í„´ìŠ¤

    Returns:
        ìƒíƒœ ì—…ë°ì´íŠ¸ ë”•ì…”ë„ˆë¦¬
    """
    logger.info(
        "Processing message",
        session_id=state["session_id"],
        current_step=state["current_step"],
    )

    # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
    user_message = _get_last_user_message(state["messages"])
    if not user_message:
        return {
            "status": "failed",
            "error": "ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
        }

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = _build_prompt(state, user_message)

    try:
        # LLM Providerì˜ generate ë©”ì„œë“œ ì‚¬ìš©
        from ...providers.base import LLMGenerationParams

        params = LLMGenerationParams(
            prompt=prompt,
            system_prompt=CHAT_SYSTEM_PROMPT,
            temperature=0.7,
            response_format="json",
        )

        result = await llm_provider.generate(params)

        if not result.success:
            logger.error("LLM generation failed", error=result.error)
            return _create_error_response(state, result.error or "LLM í˜¸ì¶œ ì‹¤íŒ¨")

        # ì‘ë‹µ íŒŒì‹± ë° ìƒíƒœ ì—…ë°ì´íŠ¸ ìƒì„±
        return _parse_llm_response(state, result.content)

    except Exception as e:
        logger.error("Message processing error", error=str(e))
        return _create_error_response(state, str(e))


def route_after_process(state: ChatState) -> str:
    """ì²˜ë¦¬ í›„ ë¼ìš°íŒ… ê²°ì •

    Args:
        state: í˜„ì¬ ëŒ€í™” ìƒíƒœ

    Returns:
        ë‹¤ìŒ ë…¸ë“œ ì´ë¦„ ("finalize" ë˜ëŠ” "wait_input")
    """
    if state.get("is_complete") or state.get("current_step") == "complete":
        return "finalize"
    return "wait_input"


async def finalize_node(state: ChatState) -> dict:
    """ëŒ€í™” ì™„ë£Œ ì²˜ë¦¬

    Args:
        state: í˜„ì¬ ëŒ€í™” ìƒíƒœ

    Returns:
        ìƒíƒœ ì—…ë°ì´íŠ¸ ë”•ì…”ë„ˆë¦¬
    """
    logger.info(
        "Finalizing conversation",
        session_id=state["session_id"],
        collected_data=state["collected_data"],
    )

    return {
        "current_step": "complete",
        "next_step": "complete",
        "is_complete": True,
        "status": "completed",
    }


# =============================================================================
# í—¬í¼ í•¨ìˆ˜ë“¤
# =============================================================================

def _get_last_user_message(messages: list) -> str | None:
    """ë©”ì‹œì§€ ëª©ë¡ì—ì„œ ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ"""
    for msg in reversed(messages):
        if isinstance(msg, HumanMessage):
            return msg.content
    return None


def _build_prompt(state: ChatState, user_message: str) -> str:
    """LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„± (í† í° ìµœì í™” + ì¶©ë¶„í•œ ì»¨í…ìŠ¤íŠ¸)
    """
    current_step = state["current_step"]

    # í™•ì •ëœ ë°ì´í„°ë§Œ ì¶”ì¶œ (null ì œì™¸)
    collected = state.get("collected_data", DEFAULT_COLLECTED_DATA)
    confirmed = {k: v for k, v in collected.items() if v is not None}

    # ê±°ë¶€ëœ í•­ëª© (ë¹„ì–´ìˆì§€ ì•Šì€ ê²ƒë§Œ)
    rejected = state.get("rejected_items", DEFAULT_REJECTED_ITEMS)
    non_empty_rejected = {k: v for k, v in rejected.items() if v}

    # ìµœê·¼ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ (ìµœëŒ€ 4ê°œ ë©”ì‹œì§€)
    recent_context = []
    for msg in state["messages"][-4:]:
        if isinstance(msg, HumanMessage):
            content = msg.content[:80] + "..." if len(msg.content) > 80 else msg.content
            recent_context.append(f"ì‚¬ìš©ì: {content}")
        elif isinstance(msg, AIMessage):
            content = msg.content[:80] + "..." if len(msg.content) > 80 else msg.content
            recent_context.append(f"AI: {content}")

    # ë‹¤ìŒ ìˆ˜ì§‘ ëŒ€ìƒ í•„ë“œ ê²°ì •
    step_to_field = {
        "greeting": "city (ë„ì‹œ)",
        "city": "spotName (ì¥ì†Œ)",
        "spot": "mainAction (í–‰ë™)",
        "action": "conceptId (ì»¨ì…‰)",
        "concept": "outfitStyle (ì˜ìƒ)",
        "outfit": "posePreference (í¬ì¦ˆ)",
        "pose": "filmType (í•„ë¦„)",
        "film": "cameraModel (ì¹´ë©”ë¼)",
    }
    next_field = step_to_field.get(current_step, "")

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt_parts = [f"ì‚¬ìš©ì ë©”ì‹œì§€: {user_message}"]

    # í™•ì • ì •ë³´ (ìˆì„ ë•Œë§Œ)
    if confirmed:
        confirmed_str = ", ".join(f"{k}={v}" for k, v in confirmed.items())
        prompt_parts.append(f"í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì •ë³´: {confirmed_str}")

    # ìˆ˜ì§‘ ì§€ì‹œ
    if next_field:
        prompt_parts.append(f"ë‹¤ìŒ ìˆ˜ì§‘ ëŒ€ìƒ: {next_field}")

    # ê±°ë¶€ í•­ëª© (ìˆì„ ë•Œë§Œ)
    if non_empty_rejected:
        rejected_items = []
        for category, items in non_empty_rejected.items():
            rejected_items.extend(items)
        if rejected_items:
            prompt_parts.append(f"ê±°ë¶€ëœ í•­ëª© (ì¬ì¶”ì²œ ê¸ˆì§€): {', '.join(rejected_items)}")

    # ìµœê·¼ ëŒ€í™” (ìˆì„ ë•Œë§Œ)
    if recent_context:
        prompt_parts.append(f"ìµœê·¼ ëŒ€í™”:\n" + "\n".join(recent_context))

    return "\n\n".join(prompt_parts)


def _extract_json_from_text(content: str) -> dict | None:
    """í…ìŠ¤íŠ¸ì—ì„œ JSON ê°ì²´ ì¶”ì¶œ

    LLMì´ JSONì„ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ê±°ë‚˜
    ì¶”ê°€ í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ë°˜í™˜í•  ê²½ìš°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    import re

    # 1. ì§ì ‘ JSON íŒŒì‹± ì‹œë„
    try:
        return json.loads(content)
    except json.JSONDecodeError:
        pass

    # 2. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ (```json ... ``` ë˜ëŠ” ``` ... ```)
    code_block_pattern = r'```(?:json)?\s*([\s\S]*?)\s*```'
    matches = re.findall(code_block_pattern, content)
    for match in matches:
        try:
            return json.loads(match.strip())
        except json.JSONDecodeError:
            continue

    # 3. í…ìŠ¤íŠ¸ ë‚´ JSON ê°ì²´ ì¶”ì¶œ ({ ... } íŒ¨í„´)
    json_pattern = r'\{[\s\S]*\}'
    matches = re.findall(json_pattern, content)
    for match in matches:
        try:
            return json.loads(match)
        except json.JSONDecodeError:
            continue

    return None


def _sanitize_reply(reply: str) -> str:
    """ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSON í˜•ì‹ ë°ì´í„° ì œê±°

    ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì‘ë‹µì—ì„œ ì‹¤ìˆ˜ë¡œ í¬í•¨ëœ JSONì„ ì œê±°í•©ë‹ˆë‹¤.
    """
    import re

    if not reply:
        return "ë‹¤ì‹œ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"

    # JSON ê°ì²´ íŒ¨í„´ ì œê±° ({ ... })
    # ì¤‘ì²©ëœ ê°ì²´ë„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ë°˜ë³µ
    sanitized = reply
    json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'

    # JSON ë¸”ë¡ ì œê±°
    sanitized = re.sub(json_pattern, '', sanitized)

    # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
    sanitized = re.sub(r'```(?:json)?[\s\S]*?```', '', sanitized)

    # ì—°ì†ëœ ê³µë°±/ì¤„ë°”ê¿ˆ ì •ë¦¬
    sanitized = re.sub(r'\n{3,}', '\n\n', sanitized)
    sanitized = sanitized.strip()

    # ë¹ˆ ì‘ë‹µì´ë©´ ê¸°ë³¸ ë©”ì‹œì§€
    if not sanitized:
        return "ë‹¤ì‹œ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"

    return sanitized


def _calculate_step_from_data(collected: dict) -> tuple[str, str, bool]:
    """ìˆ˜ì§‘ëœ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ í˜„ì¬/ë‹¤ìŒ ë‹¨ê³„ ê³„ì‚°

    Returns:
        (current_step, next_step, is_complete)
    """
    # í•„ë“œ â†’ ë‹¨ê³„ ë§¤í•‘ (ìˆœì„œëŒ€ë¡œ)
    field_to_step = [
        ("city", "city"),
        ("spotName", "spot"),
        ("mainAction", "action"),
        ("conceptId", "concept"),
        ("outfitStyle", "outfit"),
        ("posePreference", "pose"),
        ("filmType", "film"),
        ("cameraModel", "camera"),
    ]

    # ë§ˆì§€ë§‰ìœ¼ë¡œ ì±„ì›Œì§„ í•„ë“œ ì°¾ê¸°
    last_filled_step = "greeting"
    for field, step in field_to_step:
        if collected.get(field) is not None:
            last_filled_step = step

    # ë‹¤ìŒ ë‹¨ê³„ ê³„ì‚°
    next_step = STEP_TRANSITIONS.get(last_filled_step, "complete")
    is_complete = next_step == "complete"

    return last_filled_step, next_step, is_complete


def _parse_llm_response(state: ChatState, content: str) -> dict:
    """LLM ì‘ë‹µ íŒŒì‹± ë° ìƒíƒœ ì—…ë°ì´íŠ¸ ìƒì„±

    JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œì—ë„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    # JSON ì¶”ì¶œ ì‹œë„
    data = _extract_json_from_text(content)

    if data is None:
        # JSON ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ì •ì œí•˜ì—¬ ë°˜í™˜
        logger.warning("Failed to extract JSON from response")
        sanitized_content = _sanitize_reply(content)
        return {
            "assistant_reply": sanitized_content,
            "messages": [AIMessage(content=sanitized_content)],
            "status": "active",
        }

    # ìˆ˜ì§‘ëœ ë°ì´í„° ë¨¸ì§€ (ê¸°ì¡´ ê°’ ë³´ì¡´)
    new_collected = _merge_collected_data(
        state.get("collected_data", DEFAULT_COLLECTED_DATA),
        data.get("collectedData"),
    )

    # ìˆ˜ì§‘ëœ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ë‹¨ê³„ ìë™ ê³„ì‚° (LLM ì‘ë‹µë³´ë‹¤ ìš°ì„ )
    current_step, next_step, is_complete = _calculate_step_from_data(new_collected)

    # ê±°ë¶€ í•­ëª© ë¨¸ì§€
    new_rejected = _merge_rejected_items(
        state.get("rejected_items", DEFAULT_REJECTED_ITEMS),
        data.get("rejectedItems"),
    )

    # reply í•„ë“œì—ì„œë„ JSONì´ ì„ì—¬ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì •ì œ
    raw_reply = data.get("reply", "")
    reply = _sanitize_reply(raw_reply) if raw_reply else "ë‹¤ì‹œ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"

    return {
        "assistant_reply": reply,
        "current_step": current_step,
        "next_step": next_step,
        "is_complete": is_complete,
        "collected_data": new_collected,
        "rejected_items": new_rejected,
        "suggested_options": data.get("suggestedOptions", []),
        "messages": [AIMessage(content=reply)],
        "status": "completed" if is_complete else "active",
    }


def _merge_collected_data(
    existing: CollectedData | None,
    new: dict | None,
) -> CollectedData:
    """ìˆ˜ì§‘ëœ ë°ì´í„° ë¨¸ì§€ (ê¸°ì¡´ ê°’ ë³´ì¡´)"""
    result = dict(existing) if existing else dict(DEFAULT_COLLECTED_DATA)
    if new:
        for key in result:
            if new.get(key) is not None:
                result[key] = new[key]
    return result


def _merge_rejected_items(
    existing: RejectedItems | None,
    new: dict | None,
) -> RejectedItems:
    """ê±°ë¶€ í•­ëª© ë¨¸ì§€ (ì¤‘ë³µ ì œê±°)"""
    result = dict(existing) if existing else dict(DEFAULT_REJECTED_ITEMS)
    if new:
        for key in result:
            if key in new and new[key]:
                existing_items = result.get(key, [])
                result[key] = list(set(existing_items + new[key]))
    return result


def _create_error_response(state: ChatState, error: str) -> dict:
    """ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
    error_reply = "ì£„ì†¡í•´ìš”, ì ì‹œ ë¬¸ì œê°€ ìƒê²¼ì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"
    return {
        "assistant_reply": error_reply,
        "messages": [AIMessage(content=error_reply)],
        "status": "failed",
        "error": error,
    }
